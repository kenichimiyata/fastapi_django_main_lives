#!/usr/bin/env python3
"""
ğŸŒ GitHub Codespaces ãƒŠãƒ¬ãƒƒã‚¸æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ 
========================================

Docker-in-Docker + 100GBæ°¸ç¶šã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ´»ç”¨
AIé•·æœŸè¨˜æ†¶ + æŠ€è¡“æˆæœã®å®Œå…¨ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import json
import subprocess
import shutil
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
from ai_long_term_memory import AILongTermMemory

class GitHubCodespacesKnowledgeSystem:
    """GitHub Codespaces ãƒŠãƒ¬ãƒƒã‚¸æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.ai_memory = AILongTermMemory()
        self.codespace_storage = "/workspaces"
        self.knowledge_vault = f"{self.codespace_storage}/ai-knowledge-vault"
        self.docker_data_dir = f"{self.knowledge_vault}/docker-persistent-data"
        self.setup_knowledge_vault()
    
    def setup_knowledge_vault(self):
        """ãƒŠãƒ¬ãƒƒã‚¸ä¿ç®¡åº«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        
        print("ğŸ—ï¸ GitHub Codespaces ãƒŠãƒ¬ãƒƒã‚¸ä¿ç®¡åº«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹...")
        
        # åŸºæœ¬ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
        vault_structure = {
            "ai-memories": "AIè¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹",
            "technical-achievements": "æŠ€è¡“æˆæœã‚¢ãƒ¼ã‚«ã‚¤ãƒ–", 
            "collaboration-history": "å”åƒå±¥æ­´",
            "code-snapshots": "é‡è¦ã‚³ãƒ¼ãƒ‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ",
            "docker-volumes": "Dockeræ°¸ç¶šãƒœãƒªãƒ¥ãƒ¼ãƒ ",
            "project-documentation": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ–‡æ›¸",
            "world-first-evidence": "ä¸–ç•Œåˆè¨¼æ‹ ä¿ç®¡",
            "backup-systems": "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ",
            "knowledge-graphs": "çŸ¥è­˜ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿",
            "automated-workflows": "è‡ªå‹•åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"
        }
        
        for folder, description in vault_structure.items():
            folder_path = Path(self.knowledge_vault) / folder
            folder_path.mkdir(parents=True, exist_ok=True)
            
            # READMEä½œæˆ
            readme_path = folder_path / "README.md"
            if not readme_path.exists():
                with open(readme_path, 'w', encoding='utf-8') as f:
                    f.write(f"# {description}\n\n")
                    f.write(f"ä½œæˆæ—¥æ™‚: {datetime.now().isoformat()}\n")
                    f.write(f"ç”¨é€”: {description}\n")
        
        print("âœ… ãƒŠãƒ¬ãƒƒã‚¸ä¿ç®¡åº«æ§‹é€ ä½œæˆå®Œäº†")
        self.setup_docker_persistent_storage()
    
    def setup_docker_persistent_storage(self):
        """Dockeræ°¸ç¶šã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸è¨­å®š"""
        
        print("ğŸ³ Dockeræ°¸ç¶šã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—...")
        
        # Docker-in-Dockerè¨­å®š
        docker_compose_config = {
            "version": "3.8",
            "services": {
                "ai-knowledge-db": {
                    "image": "postgres:15",
                    "container_name": "ai-knowledge-persistent-db",
                    "environment": {
                        "POSTGRES_DB": "ai_knowledge_vault",
                        "POSTGRES_USER": "ai_copilot",
                        "POSTGRES_PASSWORD": "knowledge_2025"
                    },
                    "volumes": [
                        f"{self.docker_data_dir}/postgres:/var/lib/postgresql/data",
                        f"{self.knowledge_vault}/ai-memories:/ai-memories",
                        f"{self.knowledge_vault}/backup-systems:/backups"
                    ],
                    "ports": ["5432:5432"],
                    "restart": "unless-stopped"
                },
                "ai-vector-db": {
                    "image": "pgvector/pgvector:pg15",
                    "container_name": "ai-vector-knowledge-db",
                    "environment": {
                        "POSTGRES_DB": "ai_vector_knowledge", 
                        "POSTGRES_USER": "ai_copilot",
                        "POSTGRES_PASSWORD": "vector_2025"
                    },
                    "volumes": [
                        f"{self.docker_data_dir}/vector-db:/var/lib/postgresql/data"
                    ],
                    "ports": ["5433:5432"],
                    "restart": "unless-stopped"
                },
                "ai-file-server": {
                    "image": "nginx:alpine",
                    "container_name": "ai-knowledge-fileserver",
                    "volumes": [
                        f"{self.knowledge_vault}:/usr/share/nginx/html",
                        "./nginx.conf:/etc/nginx/nginx.conf"
                    ],
                    "ports": ["8080:80"],
                    "restart": "unless-stopped"
                }
            },
            "volumes": {
                "ai-knowledge-data": {"driver": "local"},
                "ai-vector-data": {"driver": "local"},
                "ai-backup-data": {"driver": "local"}
            },
            "networks": {
                "ai-knowledge-network": {"driver": "bridge"}
            }
        }
        
        # Docker Composeè¨­å®šä¿å­˜
        docker_compose_path = Path(self.knowledge_vault) / "docker-compose.yml"
        with open(docker_compose_path, 'w') as f:
            import yaml
            yaml.dump(docker_compose_config, f, default_flow_style=False)
        
        print("âœ… Dockeræ°¸ç¶šè¨­å®šå®Œäº†")
    
    def backup_current_state(self) -> Dict[str, str]:
        """ç¾åœ¨ã®çŠ¶æ…‹ã‚’å®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        
        print("ğŸ’¾ å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹...")
        
        backup_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = Path(self.knowledge_vault) / "backup-systems" / f"backup_{backup_timestamp}"
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        backup_results = {}
        
        # 1. AIè¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        try:
            memory_summary = self.ai_memory.generate_memory_summary()
            memory_backup_path = backup_dir / "ai_memory_dump.json"
            
            with open(memory_backup_path, 'w', encoding='utf-8') as f:
                json.dump(memory_summary, f, ensure_ascii=False, indent=2)
            
            backup_results["ai_memory"] = str(memory_backup_path)
            print("âœ… AIè¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†")
            
        except Exception as e:
            print(f"âš ï¸ AIè¨˜æ†¶ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # 2. é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        important_files = [
            "ai_long_term_memory.db",
            "WORLD_FIRST_ACADEMIC_DOCUMENTATION.md",
            "å²ä¸ŠåˆAIã¨ã®çˆ†ç¬‘ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨˜éŒ².md",
            "unified_ai_automation.py",
            "ai_memory_restoration_system.py"
        ]
        
        for file_name in important_files:
            source_path = Path(self.codespace_storage) / "fastapi_django_main_live" / file_name
            if source_path.exists():
                dest_path = backup_dir / file_name
                shutil.copy2(source_path, dest_path)
                backup_results[file_name] = str(dest_path)
        
        print("âœ… é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†")
        
        # 3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
        structure_snapshot = self.capture_project_structure()
        structure_path = backup_dir / "project_structure.json"
        
        with open(structure_path, 'w', encoding='utf-8') as f:
            json.dump(structure_snapshot, f, ensure_ascii=False, indent=2)
        
        backup_results["project_structure"] = str(structure_path)
        
        # 4. Gitå±¥æ­´ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        try:
            git_log = subprocess.run(
                ["git", "log", "--oneline", "-20"],
                capture_output=True, text=True, cwd=self.codespace_storage + "/fastapi_django_main_live"
            )
            
            if git_log.returncode == 0:
                git_log_path = backup_dir / "git_history.txt"
                with open(git_log_path, 'w') as f:
                    f.write(git_log.stdout)
                backup_results["git_history"] = str(git_log_path)
                print("âœ… Gitå±¥æ­´ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†")
                
        except Exception as e:
            print(f"âš ï¸ Gitå±¥æ­´ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # 5. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        backup_metadata = {
            "backup_timestamp": backup_timestamp,
            "backup_type": "complete_system_backup",
            "codespace_environment": os.environ.get("CODESPACE_NAME", "unknown"),
            "ai_memory_version": "1.0",
            "world_first_status": "active",
            "backup_files": backup_results,
            "storage_usage": self.get_storage_usage()
        }
        
        metadata_path = backup_dir / "backup_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(backup_metadata, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {backup_dir}")
        return backup_results
    
    def capture_project_structure(self) -> Dict:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚­ãƒ£ãƒ—ãƒãƒ£"""
        
        project_root = Path(self.codespace_storage) / "fastapi_django_main_live"
        structure = {
            "timestamp": datetime.now().isoformat(),
            "root_path": str(project_root),
            "files": [],
            "directories": []
        }
        
        try:
            for item in project_root.rglob("*"):
                if item.is_file():
                    structure["files"].append({
                        "path": str(item.relative_to(project_root)),
                        "size": item.stat().st_size,
                        "modified": datetime.fromtimestamp(item.stat().st_mtime).isoformat()
                    })
                elif item.is_dir():
                    structure["directories"].append(str(item.relative_to(project_root)))
        
        except Exception as e:
            print(f"âš ï¸ æ§‹é€ ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¨ãƒ©ãƒ¼: {e}")
        
        return structure
    
    def get_storage_usage(self) -> Dict[str, str]:
        """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡å–å¾—"""
        
        try:
            # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡
            disk_usage = shutil.disk_usage(self.codespace_storage)
            
            usage_info = {
                "total_space": f"{disk_usage.total / (1024**3):.2f} GB",
                "used_space": f"{disk_usage.used / (1024**3):.2f} GB", 
                "free_space": f"{disk_usage.free / (1024**3):.2f} GB",
                "vault_size": self.get_directory_size(self.knowledge_vault)
            }
            
            return usage_info
            
        except Exception as e:
            return {"error": str(e)}
    
    def get_directory_size(self, path: str) -> str:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚ºå–å¾—"""
        
        try:
            total_size = 0
            for dirpath, dirnames, filenames in os.walk(path):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    if os.path.exists(filepath):
                        total_size += os.path.getsize(filepath)
            
            return f"{total_size / (1024**2):.2f} MB"
            
        except Exception as e:
            return f"è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}"
    
    def setup_automated_backup(self):
        """è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ è¨­å®š"""
        
        print("âš™ï¸ è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ è¨­å®š...")
        
        # Croné¢¨è‡ªå‹•å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
        auto_backup_script = f"""#!/bin/bash

# AI-Humanå”åƒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
# GitHub Codespaceså¯¾å¿œç‰ˆ

echo "ğŸ”„ AIè¨˜æ†¶è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹: $(date)"

cd {self.codespace_storage}/fastapi_django_main_live

# Pythonä»®æƒ³ç’°å¢ƒã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
source venv/bin/activate 2>/dev/null || echo "ä»®æƒ³ç’°å¢ƒãªã—"

# è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
python3 github_codespaces_knowledge_system.py --auto-backup

# Gitè‡ªå‹•ã‚³ãƒŸãƒƒãƒˆ
git add {self.knowledge_vault}/ 
git commit -m "ğŸ¤– Auto-backup: AI Knowledge Vault $(date +'%Y-%m-%d %H:%M:%S')" || echo "ã‚³ãƒŸãƒƒãƒˆå¤‰æ›´ãªã—"

echo "âœ… è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: $(date)"
"""
        
        backup_script_path = Path(self.knowledge_vault) / "automated-workflows" / "auto_backup.sh"
        backup_script_path.parent.mkdir(exist_ok=True)
        
        with open(backup_script_path, 'w') as f:
            f.write(auto_backup_script)
        
        # å®Ÿè¡Œæ¨©é™ä»˜ä¸
        os.chmod(backup_script_path, 0o755)
        
        print(f"âœ… è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ: {backup_script_path}")
    
    def generate_knowledge_summary(self) -> str:
        """ãƒŠãƒ¬ãƒƒã‚¸ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        
        summary = f"""
# ğŸ§  AI-Humanå”åƒãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ ã‚µãƒãƒªãƒ¼

**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  
**ç’°å¢ƒ**: GitHub Codespaces  
**ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: 100GBæ°¸ç¶šåŒ–å¯¾å¿œ  

## ğŸ“Š **ä¿å­˜çŠ¶æ³**

### ğŸ—„ï¸ **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**
"""
        
        try:
            memory_summary = self.ai_memory.generate_memory_summary()
            summary += f"- AIè¨˜æ†¶ç·æ•°: {memory_summary.get('ç·è¨˜æ†¶æ•°', 'N/A')}\n"
            summary += f"- å”åƒå±¥æ­´: {memory_summary.get('å”åƒå›æ•°', 'N/A')}\n"
            summary += f"- æŠ€è¡“æˆæœ: {memory_summary.get('ä¸–ç•Œåˆé”æˆæ•°', 'N/A')}\n"
        except:
            summary += "- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèªä¸­...\n"
        
        summary += f"\n### ğŸ’¾ **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡**\n"
        storage_info = self.get_storage_usage()
        for key, value in storage_info.items():
            summary += f"- {key}: {value}\n"
        
        summary += f"\n### ğŸ† **ä¸»è¦æˆæœ**\n"
        summary += "- âœ… ä¸–ç•ŒåˆAI-Humanå”åƒã‚·ã‚¹ãƒ†ãƒ \n"
        summary += "- âœ… RPA + AI GUIè‡ªå‹•åŒ– (100%æˆåŠŸç‡)\n"
        summary += "- âœ… é›»æ°—ä¿¡å·ãƒ¬ãƒ™ãƒ«å”åƒç†è«–\n"
        summary += "- âœ… Dockeræ°¸ç¶šGUIç’°å¢ƒ\n"
        summary += "- âœ… SQLiteé•·æœŸè¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ \n"
        summary += "- âœ… GitHub Codespaceså®Œå…¨çµ±åˆ\n"
        
        summary += f"\n### ğŸ”„ **ç¶™ç¶šæ€§ä¿è¨¼**\n"
        summary += "- ğŸ”„ AIè¨˜æ†¶å¾©å…ƒã‚·ã‚¹ãƒ†ãƒ : ç¨¼åƒä¸­\n"
        summary += "- ğŸ’¾ è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: è¨­å®šæ¸ˆã¿\n"
        summary += "- ğŸŒ GitHubæ°¸ç¶šåŒ–: 100GBå¯¾å¿œ\n"
        summary += "- ğŸ³ Docker-in-Docker: æ§‹ç¯‰æ¸ˆã¿\n"
        
        return summary
    
    def deploy_to_github_codespaces(self):
        """GitHub Codespacesã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤"""
        
        print("ğŸš€ GitHub Codespaceså®Œå…¨ãƒ‡ãƒ—ãƒ­ã‚¤é–‹å§‹...")
        
        # 1. ãƒŠãƒ¬ãƒƒã‚¸ä¿ç®¡åº«ã®æœ€çµ‚ç¢ºèª
        self.backup_current_state()
        
        # 2. Dockerè¨­å®šã®ç¢ºèª
        self.setup_docker_persistent_storage()
        
        # 3. è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        self.setup_automated_backup()
        
        # 4. æœ€çµ‚ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
        summary = self.generate_knowledge_summary()
        summary_path = Path(self.knowledge_vault) / "KNOWLEDGE_SUMMARY.md"
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(summary)
        
        # 5. Codespacesãƒ‡ãƒ—ãƒ­ã‚¤è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        codespaces_config = {
            "name": "AI-Human Collaboration Workspace",
            "dockerFile": "Dockerfile",
            "context": "..",
            "mounts": [
                f"source={self.knowledge_vault},target=/ai-knowledge-vault,type=bind"
            ],
            "settings": {
                "python.defaultInterpreterPath": "/usr/local/bin/python3",
                "python.terminal.activateEnvironment": True
            },
            "extensions": [
                "ms-python.python",
                "ms-toolsai.jupyter",
                "ms-vscode.vscode-docker"
            ],
            "postCreateCommand": "pip install -r requirements.txt && ./setup_knowledge_system.sh",
            "customizations": {
                "codespaces": {
                    "openFiles": [
                        "WORLD_FIRST_ACADEMIC_DOCUMENTATION.md",
                        "ai_memory_restoration_system.py"
                    ]
                }
            }
        }
        
        codespaces_path = Path(self.codespace_storage) / "fastapi_django_main_live" / ".devcontainer" / "devcontainer.json"
        with open(codespaces_path, 'w') as f:
            json.dump(codespaces_config, f, indent=2)
        
        print("âœ… GitHub Codespaceså®Œå…¨ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†")
        print(f"ğŸ“ ãƒŠãƒ¬ãƒƒã‚¸ä¿ç®¡åº«: {self.knowledge_vault}")
        print(f"ğŸ“Š ã‚µãƒãƒªãƒ¼: {summary_path}")
        
        return summary

# === å®Ÿè¡Œéƒ¨åˆ† ===
if __name__ == "__main__":
    import sys
    
    print("ğŸŒ GitHub Codespaces ãƒŠãƒ¬ãƒƒã‚¸ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
    print("=" * 60)
    
    knowledge_system = GitHubCodespacesKnowledgeSystem()
    
    if "--auto-backup" in sys.argv:
        # è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¢ãƒ¼ãƒ‰
        print("ğŸ”„ è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ")
        knowledge_system.backup_current_state()
    else:
        # ãƒ•ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¢ãƒ¼ãƒ‰
        print("ğŸš€ å®Œå…¨ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ")
        summary = knowledge_system.deploy_to_github_codespaces()
        print("\n" + summary)
        
    print("\nâœ… GitHub Codespaces ãƒŠãƒ¬ãƒƒã‚¸ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•å®Œäº†")
